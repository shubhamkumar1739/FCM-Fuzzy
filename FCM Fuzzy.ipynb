{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Floating Centroid Method with Fuzzy C Means Algorithm</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activate(z,activation) :\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation_step(a_prev, weights, biases, activation) :\n",
    "    '''\n",
    "    params :\n",
    "        a_prev : (C[L-1],m)\n",
    "        weights : (C[L],C[L-1])\n",
    "        biases : (C[L],1)\n",
    "    '''\n",
    "    z = np.dot(weights, a_prev) + biases\n",
    "    a = activate(z, activation) \n",
    "    \n",
    "    return z,a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(activations, z_values, weights, biases, a_funcs) :\n",
    "    '''\n",
    "    params :\n",
    "        activations :  a list of activations of all layers\n",
    "        z_values : a list of z values of all layers (dummy for 0th layer)\n",
    "        weights : list of weights of all layers\n",
    "        biases : list of biases of all layers\n",
    "        a_funcs : list of activation functions for all layers (dummy for 0th layer)\n",
    "    '''\n",
    "    L = len(activations)\n",
    "    \n",
    "    for i in range(1, L) :\n",
    "        weight = weights[i]\n",
    "        bias = biases[i]\n",
    "        activation = activations[i - 1]\n",
    "        a_func = a_funcs[i]\n",
    "        \n",
    "        z, a = forward_propagation_step(activation, weight, bias, a_func)\n",
    "        z_values[i] = z\n",
    "        activations[i] = a\n",
    "        \n",
    "        return z_values, activations, weights, biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d_activate(z, activation) :\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_propagation_step(l, learning_rate, z_value, weights, biases, \n",
    "                              activation, delta, a_next, lamb,C_S, C_N, a, epsilon) :\n",
    "    '''\n",
    "    params :\n",
    "        l : layer index\n",
    "        learning rate : learning rate\n",
    "        z_value : (C[L], m)\n",
    "        weights : (C[L],C[L-1])\n",
    "        biases : (C[L-1],1)\n",
    "        activation : activation function\n",
    "        delta : (C[L+1],m)\n",
    "    '''\n",
    "    L = None # TODO : update\n",
    "    delta = None\n",
    "    \n",
    "    if l == L :\n",
    "        delta_l = d_activate(z_value,activation) * ((C_S - a) - (epsilon * (C_N - a)))\n",
    "        return delta, None, None\n",
    "    else :\n",
    "        delta_l = np.dot(weights[l + 1],delta) * d_activate(z_value,activation) \n",
    "        \n",
    "    dw = learning_rate * (delta_l * a_next - (lamb * weight))\n",
    "    weights = weights - dw \n",
    "    \n",
    "    db = -learning_rate * delta_l\n",
    "    biases = biases - db\n",
    "    \n",
    "    return delta_l, weights, bisaes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_propagation(activations, z_values, weights, biases, learning_rate, epsilon, lamb, C_S, C_N) :\n",
    "    \n",
    "    L = len(weights)\n",
    "    delta = None\n",
    "    \n",
    "    i = L\n",
    "    while i > 0 :\n",
    "        \n",
    "        weight = weights[i]\n",
    "        bias = biases[i]\n",
    "        \n",
    "        a_next = None\n",
    "        if i < L :\n",
    "            a_next = activations[i+1]\n",
    "        \n",
    "        z_value = z_values[i]\n",
    "        a_func = a_funcs[i]\n",
    "        \n",
    "        delta, w , b = backward_propagation_step(i, learning_rate, z_value, weight, bias, activation, \n",
    "                                                 delta, a_next, lamb, C_S, C_N, activations[i], epsilon)\n",
    "        \n",
    "        weights[i] = w\n",
    "        biases[i] = b\n",
    "        \n",
    "        i -= 1\n",
    "        \n",
    "        return weights, biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist(X, V) :\n",
    "    '''\n",
    "    parmas :\n",
    "        X : (m,N)\n",
    "        V : (C,N)\n",
    "    '''\n",
    "    N = X.shape[1]\n",
    "    m = X.shape[0]\n",
    "    C = V.shape[0]\n",
    "    distance = np.zeros((m, N, C))\n",
    "    d = np.zeros((m,C))\n",
    "    \n",
    "    for i in range(0, C) :\n",
    "        distance[:, :, i] = X - np.reshape(V[i,:],(1,N))\n",
    "        distance[:, : ,i] = np.power(distance[:,:,i],2)\n",
    "        d[:,i] = np.sum(distance[:,:,i], axis = 1)\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_membership(X , V, r) :\n",
    "    \n",
    "    m = X.shape[0]\n",
    "    C = V.shape[0]\n",
    "    e = 0.000006\n",
    "    \n",
    "    d = dist(X,V)\n",
    "    u = np.zeros((m,C))\n",
    "    \n",
    "    num = np.power(d, 1/ (r - 1))\n",
    "    denom = np.sum(np.power(num, -1),axis = 1)\n",
    "    denom = np.reshape(denom, (denom.shape[0],1))\n",
    "    \n",
    "    u = np.power(num * denom, -1)\n",
    "    \n",
    "    for i in range(m) :\n",
    "        for j in range(C) :\n",
    "            if np.isnan(u[i][j]) :\n",
    "                for k in range(C) :\n",
    "                    if d[i][k] < e :\n",
    "                        u[i][k] = 1\n",
    "                    else :\n",
    "                        u[i][k] = 0\n",
    "                break\n",
    "    \n",
    "    return u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_centroids(X,u,r) :\n",
    "    \n",
    "    N = X.shape[1]\n",
    "    C = u.shape[1]\n",
    "    \n",
    "    u_r = np.power(u,r)\n",
    "    denom = np.sum(u_r, axis = 0)\n",
    "    denom = np.reshape(denom,(denom.shape[0],1))\n",
    "    \n",
    "    V = np.dot(X.transpose(),u_r).transpose()\n",
    "    V = V / denom\n",
    "    \n",
    "    return V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def init_centroids(X, C) :\n",
    "    \n",
    "    m = X.shape[0]\n",
    "    N = X.shape[1]\n",
    "    \n",
    "    selects = random.sample([i for i in range(m)], C)\n",
    "    \n",
    "    V = np.zeros((C,N))\n",
    "    \n",
    "    for i in range(C) :\n",
    "        V[i, :] = X[selects[i],:]\n",
    "        \n",
    "    return V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_clusters(X_input, r, max_iters, num_clusters, Y, num_classes) :\n",
    "    '''\n",
    "    returns :\n",
    "        cluster_count : (C,num_classes)\n",
    "                        # of classes per cluster\n",
    "    '''\n",
    "    X = X_input.transpose()\n",
    "    m = X.shape[0]\n",
    "    N = X.shape[1]\n",
    "    C = num_clusters\n",
    "    \n",
    "    V = init_centroids(X, C)\n",
    "    \n",
    "    for i in range(max_iters) :\n",
    "        u = calculate_membership(X, V, r)\n",
    "        V = move_centroids(X, u, r)    \n",
    "    \n",
    "    clusters = np.argmax(u, axis = 1) \n",
    "    \n",
    "    cluster_count = np.zeros((C,num_classes))\n",
    "    \n",
    "    for i in range(0,m) :\n",
    "        cluster_count[clusters[i]][Y[i]] += 1\n",
    "        \n",
    "    return V, u, clusters, cluster_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_centroids(clusters, cluster_count) :\n",
    "    \n",
    "    C = cluster_count.shape[0]\n",
    "    color = [0 for i in range(0, C)]\n",
    "    \n",
    "    for i in range(0, C) :\n",
    "        color[i] = np.argmax(cluster_count, axis = 1)\n",
    "        \n",
    "    return color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(a , b) :\n",
    "    \n",
    "    c = a - b\n",
    "    c = np.power(c, 2)\n",
    "    s = np.sqrt(np.sum(c, axis = 1))\n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Cs(color, cluster_count, centroids, mapped_val, Y) :\n",
    "    '''\n",
    "    params : \n",
    "            Y : actual class of i'th example\n",
    "    '''\n",
    "    \n",
    "    C = cluster_count.shape[0]\n",
    "    \n",
    "    C_S = 0\n",
    "    C_N = 0\n",
    "    min_S = None\n",
    "    ind_S = None\n",
    "    min_N = None\n",
    "    ind_N = None\n",
    "    \n",
    "    for i in range(0, C) :\n",
    "        d = euclidean_distance(mapped_val, centroids[i])\n",
    "        if Y == color[i] :\n",
    "            if min_S == None :\n",
    "                min_S = d\n",
    "                ind_S = i\n",
    "            elif min_S > d :\n",
    "                min_S = d\n",
    "                ind_S = i\n",
    "        else :\n",
    "            if min_N == None :\n",
    "                min_N = d\n",
    "                ind_N = i\n",
    "            elif min_N > d :\n",
    "                min_N = d\n",
    "                ind_N = i\n",
    "    \n",
    "    if min_S == None :\n",
    "        \n",
    "        max_percent = 0\n",
    "        for i in range(0, C) :\n",
    "            d = euclidean_distance(mapped_val, centroids[i])\n",
    "            percent = cluster_count[i][Y] / np.sum(cluster_count[i], axis = 1)\n",
    "            \n",
    "            if percent > max_percent :\n",
    "                max_percent = percent\n",
    "                min_S = d\n",
    "                ind_S = i\n",
    "            \n",
    "    if min_N == None :\n",
    "        \n",
    "        max_percent = 0\n",
    "        for i in range(0, C) :\n",
    "            d = euclidean_distance(mapped_val, centroids[i])\n",
    "            total = np.sum(cluster_count[i], axis = 1)\n",
    "            percent = (total - cluster_count[i][Y]) / total\n",
    "            \n",
    "            if percent > max_percent :\n",
    "                max_percent = percent\n",
    "                min_N = d\n",
    "                ind_N = i\n",
    "    \n",
    "    return centroids[ind_S], centroids[ind_N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X, Y, max_iters_grad_desc, max_iters_clustering, r, learning_rate, epsilon, \n",
    "                     lamb, layers, a_funcs, num_clusters) :\n",
    "    \n",
    "    num_classes = len(set(Y))\n",
    "    L = len(layers) + 1\n",
    "    \n",
    "    activations = [i for i in range(L)]\n",
    "    activations[0] = X\n",
    "    z_values = [i for i in range(L)]\n",
    "    \n",
    "    weights = []\n",
    "    biases = []\n",
    "    \n",
    "    for i in range(1,len(layers)) :\n",
    "        weights.append(np.zeros((layers[i], layers[i] - 1)))\n",
    "        biases.append(np.ones((layers[i],1)))\n",
    "        \n",
    "    for i in range(0, max_iters_grad_desc) :\n",
    "        \n",
    "        z_values, activations, weights, biases = forward_propagation(activations = activations, \n",
    "                                                                     z_values = z_values, weights = weights,\n",
    "                                                                    biases = biases, a_funcs = a_funcs)\n",
    "        \n",
    "        V, u, clusters, cluster_count = build_clusters(X, r , max_iters_clustering, num_clusters, Y, num_classes)\n",
    "        \n",
    "        #compute costs\n",
    "        colors = color_centroids(clusters, cluster_count)\n",
    "        \n",
    "        C_S, C_N = getCs(colors, cluster_count, V, activations[L], Y)\n",
    "        \n",
    "        weights, biases = backward_propagation(activations, z_values, weights, biases, learning_rate,\n",
    "                                              epsilon, lamb, C_S, C_N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Datasets</h1>\n",
    "<p>Pima Indians Diabetes Dataset</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(pd.read_csv('~/Documents/Papers/FCM-Fuzzy/Datasets/pima-indians-diabetes-database/diabetes.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 9)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to numpy array\n",
    "X_input = data.values\n",
    "X_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = X_input[:,8] # target labels\n",
    "Y = [int(i) for i in Y]\n",
    "\n",
    "X = X_input[:,:7].transpose() # X values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in power\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/root/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:14: RuntimeWarning: invalid value encountered in multiply\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "V, u, clusters, cluster_count = build_clusters(X, r = 2, max_iters= 1000, num_clusters = 5, num_classes = 2, Y = Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[102.,  43.],\n",
       "       [141.,  97.],\n",
       "       [ 91.,  12.],\n",
       "       [ 71.,  58.],\n",
       "       [ 95.,  58.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
